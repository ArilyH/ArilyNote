#LLM #SE
# RQ
RQ1：迄今为止，为了解决软件工程任务，使用了哪些LLM方法？（Methodology&LLMs）
RQ2：在LLM中，与软件工程相关的数据集是如何收集、预处理和使用的？（Datasets）
RQ3：用于优化和评估 LLM4SE 的技术有哪些？（Optimization&Evaluation）
RQ4：迄今为止，使用 LLM4SE 有效地解决了哪些软件工程任务？（Tasks&Goals）


# Keywords
## SE
软件工程、软件开发、软件测试、软件维护*、SE、软件生命周期、软件设计*、代码表示、代码生成、代码注释生成、代码搜索、代码本地化、代码补全、代码摘要、方法名生成、错误检测、错误定位、漏洞检测、测试技术、测试用例生成、程序分析、错误分类、缺陷预测、程序修复、代码克隆检测、错误报告、软件质量评估、SATD 检测、代码异味检测、编译相关、代码审查、软件分类、代码分类、代码变更、事件检测、需求提取、需求可追溯性、需求验证、努力成本预测、GitHub/Github 挖掘、SO（Stack Overflow）/SO 挖掘、应用挖掘、标签/标签挖掘、基于开发者的挖掘

## LLM
LLM，LM，PLM，预训练，NLP，ML，DL，AI，Transformer，BERT，CodeX，GPT，T5，注意力模型，迁移学习，NN，ChatGPT

# Topics
![[Pasted image 20250304054053.png]]
![[Pasted image 20250304054320.png]]


# RQ 1
## RQ 1.1 目前的LLM4SE任务中使用的LLM
### EncoderOnly（理解型任务）
仅利用模型编码器组件的神经网络架构。处理和编码输入，将其转换为隐藏feature，捕捉词语之间的关系和句子的整体上下文。如BERT。在需要细微理解整个句子或代码片段的任务中可以使用编码器大模型。例如代码审查、错误报告理解和与代码实体相关的命名实体识别。
训练过程一般采用掩码语言模型任务（预测token）
目前的LLM4SE任务中有多个基于BERT的研究，
如CodeBERT[92]：整合了一种标记预测方案，通过预测后续标记来理解代码，从而增强了其在代码补全和错误检测等任务中对编程语言的理解。其目标是通过联合学习自然语言与编程语言的语义关联，支持代码搜索、生成等跨模态任务
GraphCodeBERT：将代码元素之间的关系识别为图（数据流图），引入了数据流图边类型预测，可以更好地学习代码和程序结构之间的语义关联。GraphCoderBERT 能够利用代码结构，提高其在代码摘要和程序分析等任务中的有效性。

### Encoder-Decoder（理解&生成）
结合编码器和解码器的LLM。编码器将输入句子编码成feature，有效地捕捉其底层结构和语义。这弥合了不同输入和输出格式之间的差距。解码器利用feature生成目标输出文本，将抽象表示转化为具体且与上下文相关的表达。如T5 和 CodeT5 等模型体现了这种架构。适用于代摘要等（理解&生成任务）
训练过程一般采用Span Corruption（会Mask连续一段，按顺序预测token）

CodeT5：基于T5的结构，在三个任务（代码预测、标识符区分、标识符预测）预训练，并通过下游任务微调适应具体场景。
AlphaCode：核心创新在于推理阶段的生成-筛选策略：针对同一题目，生成 ​**数百万个候选代码**​（例如 100 万条 Python 代码）。用题目提供的示例测试用例快速验证代码。淘汰 ​**99% 以上的错误代码**，仅保留通过示例测试的代码（约 1 万条）。对剩余代码进行 ​**聚类分析**，基于代码结构或输出结果相似性分组。从每个聚类中选取 ​**代表性代码**​ 提交，避免重复提交相似代码。

## DecoderOnly（理解型任务）
