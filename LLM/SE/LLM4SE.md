#LLM #SE
# RQ
RQ1：迄今为止，为了解决软件工程任务，使用了哪些LLM方法？（Methodology&LLMs）
RQ2：在LLM中，与软件工程相关的数据集是如何收集、预处理和使用的？（Datasets）
RQ3：用于优化和评估 LLM4SE 的技术有哪些？（Optimization&Evaluation）
RQ4：迄今为止，使用 LLM4SE 有效地解决了哪些软件工程任务？（Tasks&Goals）


# Keywords
## SE
软件工程、软件开发、软件测试、软件维护*、SE、软件生命周期、软件设计*、代码表示、代码生成、代码注释生成、代码搜索、代码本地化、代码补全、代码摘要、方法名生成、错误检测、错误定位、漏洞检测、测试技术、测试用例生成、程序分析、错误分类、缺陷预测、程序修复、代码克隆检测、错误报告、软件质量评估、SATD 检测、代码异味检测、编译相关、代码审查、软件分类、代码分类、代码变更、事件检测、需求提取、需求可追溯性、需求验证、努力成本预测、GitHub/Github 挖掘、SO（Stack Overflow）/SO 挖掘、应用挖掘、标签/标签挖掘、基于开发者的挖掘

## LLM
LLM，LM，PLM，预训练，NLP，ML，DL，AI，Transformer，BERT，CodeX，GPT，T5，注意力模型，迁移学习，NN，ChatGPT

# Topics
![[Pasted image 20250304054053.png]]
![[Pasted image 20250304054320.png]]


# RQ 1 LLMs
## RQ 1.1 目前的LLM4SE任务中使用的LLM
### EncoderOnly（理解型任务）
仅利用模型编码器组件的神经网络架构。处理和编码输入，将其转换为隐藏feature，捕捉词语之间的关系和句子的整体上下文。如BERT。在需要细微理解整个句子或代码片段的任务中可以使用编码器大模型。例如代码审查、错误报告理解和与代码实体相关的命名实体识别。
训练过程一般采用掩码语言模型任务（预测token）
目前的LLM4SE任务中有多个基于BERT的研究，
如CodeBERT[92]：整合了一种标记预测方案，通过预测后续标记来理解代码，从而增强了其在代码补全和错误检测等任务中对编程语言的理解。其目标是通过联合学习自然语言与编程语言的语义关联，支持代码搜索、生成等跨模态任务
GraphCodeBERT：将代码元素之间的关系识别为图（数据流图），引入了数据流图边类型预测，可以更好地学习代码和程序结构之间的语义关联。GraphCoderBERT 能够利用代码结构，提高其在代码摘要和程序分析等任务中的有效性。

### Encoder-Decoder（理解&生成）
结合编码器和解码器的LLM。编码器将输入句子编码成feature，有效地捕捉其底层结构和语义。这弥合了不同输入和输出格式之间的差距。解码器利用feature生成目标输出文本，将抽象表示转化为具体且与上下文相关的表达。如T5 和 CodeT5 等模型体现了这种架构。适用于代码摘要等（理解&生成任务）
训练过程一般采用Span Corruption（会Mask连续一段，按顺序预测token）

CodeT5：基于T5的结构，在三个任务（代码预测、标识符区分、标识符预测）预训练，并通过下游任务微调适应具体场景。
AlphaCode：核心创新在于推理阶段的生成-筛选策略：针对同一题目，生成 ​**数百万个候选代码**​（例如 100 万条 Python 代码）。用题目提供的示例测试用例快速验证代码。淘汰 ​**99% 以上的错误代码**，仅保留通过示例测试的代码（约 1 万条）。对剩余代码进行 ​**聚类分析**，基于代码结构或输出结果相似性分组。从每个聚类中选取 ​**代表性代码**​ 提交，避免重复提交相似代码。

## DecoderOnly（生成型任务）
仅使用解码器模块生成目标输出文本，遵循强调序列预测的独特训练范式。仅解码器架构通过自回归（Autoregressive）方式生成目标文本。与编码器-解码器架构不同，它无需独立的编码器处理输入，而是将输入和输出统一为连续的序列。如GPT Copilot。仅解码器LLMs通常更适合各种生成任务，如代码生成和代码补全。这些模型通常可以从几个示例或简单指令中执行下游任务，而无需添加预测头或微调。生成结果依赖提示设计（Prompt Engineering），不稳定。对复杂任务（如多步推理）性能可能不如微调模型。适用于代码生成。
典型工作如InstructGPT（RLHF&SFT）、CodeX&Copilot（代码&IDE数据微调）。

## Trend
![[Pasted image 20250304165500.png]]
2020年集中在仅编码器模型（BERT等）OnSE研究。
2021年开始出现较多仅解码器模型forSE研究。
2022年（GPT3）后LLM4SE方向研究激增，且仅解码器模型逐渐占领统治地位。

显著趋势是针对精确软件工程（SE）任务的LLMs定制。通过使用针对特定功能（如错误检测或代码审查）定制的数据集微调模型，研究能够实现显著的性能提升。


## Summary
每个LLM架构在软件工程任务中都有其特定的用途，其中仅编码器LLMs专注于全面理解，编码器-解码器LLMs用于需要理解输入信息后进行内容生成的任务，而仅解码器LLMs更适合生成任务。
最广泛使用的LLMs是仅使用解码器架构。

# RQ2 DataSets
![[Pasted image 20250304192507.png]]
### Collecting
数据源分为四类：开源数据集、收集数据集、构建数据集和工业数据集。
开源数据集如：
- ​**HumanEval**：包含164个手工编写的Python编程问题及其单元测试，用于评估代码生成能力。
- **CodeSearchNet**：涵盖多种编程语言（Python、Java等）的代码片段与自然语言查询配对。
 ​**高可信度**：经学术界验证，标注质量可靠。**可复现性**：支持研究复现和结果对比。**领域限制**：可能无法覆盖特定场景。
 
收集数据集如从​**Stack Overflow**爬取问答帖构建代码修复数据集/**GitHub Issues**提取用户反馈生成需求描述与代码的映射。数据来源广，费时费力且需清洗无关内容。

构建数据集通过人工标注、数据增强或合成方法改造现有数据，以满足特定需求。可以直接适配研究目标、平衡数据分布。但费时费力，且合成数据可能与真实场景存在差距。

工业数据集是来自企业内部的私有数据，包含业务代码、用户日志等敏感信息。直接反映实际场景需求。获取此类数据可能需要保密协议和其他法律保障来保护商业利益。每种数据集类型都提供了独特的优势和挑战，选择它们应指导当前研究项目的具体需求和限制。


