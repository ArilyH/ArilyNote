学长您好，这里是有关之前未结论文的进展：
有关CIFAR10-VGG16上的效果：数据集上我们的方法效果比较一般，而且CMG-PGD上一直调不好，我在想是只放原始数据集的效果/还是放了说CMGFuzz在低质量数据集上效果一般/还是干脆就不放了。
![[Pasted image 20250303214851.png]]![[Pasted image 20250303214913.png]]

下面是STL10-MobileNet的效果：看着还行（？）
![[Pasted image 20250303215051.png]]![[Pasted image 20250303215101.png]]

有关参数调整实验：
在flower17上做的参数调整。（就……好像对参数不太敏感，至少没什么明显的规律吧？）
{'05': {'ORG': 83.52941176470588}, '10': {'ORG': 82.3529411764706}, '15': {'ORG': 79.41176470588235}, '20': {'ORG': 85.88235294117646}, '25': {'ORG': 84.70588235294117}, '30': {'ORG': 81.76470588235294}, '35': {'ORG': 81.76470588235294}, '40': {'ORG': 83.52941176470588}}

flws-05: nbc:1.0 snac:0.7292771935462952 kmnc:0.8339929580688477 tknc:0.09489408135414124
flws-10: nbc:1.0 snac:0.7391353249549866 kmnc:0.839190661907196 tknc:0.09587237238883972
flws-15: nbc:1.0 snac:0.7254769206047058 kmnc:0.837550163269043 tknc:0.09444256126880646
flws-20: nbc:1.0 snac:0.7288632988929749 kmnc:0.8377627730369568 tknc:0.09485645592212677
flws-25: nbc:1.0 snac:0.7141889929771423 kmnc:0.8326579928398132 tknc:0.09485645592212677
flws-30: nbc:1.0 snac:0.7412047982215881 kmnc:0.8395594358444214 tknc:0.09485645592212677
flws-35: nbc:1.0 snac:0.7255898118019104 kmnc:0.837314248085022 tknc:0.09579712152481079
flws-40: nbc:1.0 snac:0.7266809940338135 kmnc:0.8396034240722656 tknc:0.09583474695682526

有关JudgeLLM：
之前做过在正确response上引入错误扰动后影响JudgeLLM评估质量的实验，我想JudgeLLM对扰动后的正确response敏感是正常的。
所以后面尝试做了这样一套方法：
首先是根据词库做了一套同义词网，结构大概是这样的：
14578: {'insufficiently': 0}, 14579: {'freedmen': 0}, 14580: {'Proper': 22, 'proper': 27, 'right': 2}, 14581: {'swaying': 0, 'rock': 0, 'sway': 0, 'shake': 0, 'swing': 4, 'carry': 3, 'persuade': 0}, 14582: {'outrages': 0, 'indignation': 0, 'outrage': 2, 'scandal': 0, 'shock': 0, 'offend': 2, 'profane': 2, 'violate': 1, 'rape': 2, 'assault': 0, 'dishonor': 3}, 14583: {'obeying': 0, 'obey': 0}, 14584: {'comprehending': 0, 'grok': 0, 'comprehend': 1, 'savvy': 1, 'dig': 0, 'grasp': 0, 'compass': 2, 'apprehend': 0, 'perceive': 0, 'embrace': 1, 'encompass': 0, 'cover': 0}

在给定的数据集上（比如JudgeBench）移除掉Coding相关的任务（因为Coding的response引入同义词替换质量的变化是很大的），shuffle后划分出20%训练集。
在给定的JudgeLLM（如deepseek7B llama3 8B qwen2.5 7B）上，给定一对response，对JudgeLLM判断为"劣"的response的每个词逐一做同义词替换，比如：
对response：“Proper thing XXX”
14580: {'Proper': 22, 'proper': 27, 'right': 2},
将Proper替换为proper 观察Judge是否变化为优，是则同义词链表14580中'Proper'分数变为23。
如此往复。

